{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SPRAWDZIC WYJSCIE Z NASZEJ FPN JESLI DAMY INNY TENSOR NA WEJSCIE 640x640\n",
    "I RESNETA tez czy zmienia sie liczba paraemtrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-06T11:34:02.859133Z",
     "start_time": "2023-12-06T11:33:59.474661Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchsummary import summary\n",
    "from model.ResNet50 import ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-06T10:21:16.510052Z",
     "start_time": "2023-12-06T10:21:16.508397Z"
    }
   },
   "outputs": [],
   "source": [
    "PATH_MODEL = \"data/model/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-06T10:21:18.618893Z",
     "start_time": "2023-12-06T10:21:18.258525Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to C:\\Users\\jkwia/.cache\\torch\\hub\\checkpoints\\resnet50-11ad3fa6.pth\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 97.8M/97.8M [00:43<00:00, 2.37MB/s]\n"
     ]
    }
   ],
   "source": [
    "model = ResNet50()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-06T10:21:19.302157Z",
     "start_time": "2023-12-06T10:21:19.252615Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jkwia\\anaconda3\\lib\\site-packages\\torch\\cuda\\__init__.py:141: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 9020). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\c10\\cuda\\CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-06T10:21:20.005510Z",
     "start_time": "2023-12-06T10:21:19.825269Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet50(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-06T10:21:28.680758Z",
     "start_time": "2023-12-06T10:21:23.994121Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048, 16, 25])\n"
     ]
    }
   ],
   "source": [
    "input_tensor = torch.randn(1,3, 512, 800).to(device)\n",
    "output = model(input_tensor)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-06T10:21:32.071540Z",
     "start_time": "2023-12-06T10:21:32.014133Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
      "              ReLU-3         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
      "            Conv2d-5           [-1, 64, 56, 56]           4,096\n",
      "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
      "              ReLU-7           [-1, 64, 56, 56]               0\n",
      "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
      "             ReLU-10           [-1, 64, 56, 56]               0\n",
      "           Conv2d-11          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-12          [-1, 256, 56, 56]             512\n",
      "           Conv2d-13          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-14          [-1, 256, 56, 56]             512\n",
      "             ReLU-15          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-16          [-1, 256, 56, 56]               0\n",
      "           Conv2d-17           [-1, 64, 56, 56]          16,384\n",
      "      BatchNorm2d-18           [-1, 64, 56, 56]             128\n",
      "             ReLU-19           [-1, 64, 56, 56]               0\n",
      "           Conv2d-20           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-21           [-1, 64, 56, 56]             128\n",
      "             ReLU-22           [-1, 64, 56, 56]               0\n",
      "           Conv2d-23          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-24          [-1, 256, 56, 56]             512\n",
      "             ReLU-25          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-26          [-1, 256, 56, 56]               0\n",
      "           Conv2d-27           [-1, 64, 56, 56]          16,384\n",
      "      BatchNorm2d-28           [-1, 64, 56, 56]             128\n",
      "             ReLU-29           [-1, 64, 56, 56]               0\n",
      "           Conv2d-30           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-31           [-1, 64, 56, 56]             128\n",
      "             ReLU-32           [-1, 64, 56, 56]               0\n",
      "           Conv2d-33          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-34          [-1, 256, 56, 56]             512\n",
      "             ReLU-35          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-36          [-1, 256, 56, 56]               0\n",
      "           Conv2d-37          [-1, 128, 56, 56]          32,768\n",
      "      BatchNorm2d-38          [-1, 128, 56, 56]             256\n",
      "             ReLU-39          [-1, 128, 56, 56]               0\n",
      "           Conv2d-40          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-41          [-1, 128, 28, 28]             256\n",
      "             ReLU-42          [-1, 128, 28, 28]               0\n",
      "           Conv2d-43          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-44          [-1, 512, 28, 28]           1,024\n",
      "           Conv2d-45          [-1, 512, 28, 28]         131,072\n",
      "      BatchNorm2d-46          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-47          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-48          [-1, 512, 28, 28]               0\n",
      "           Conv2d-49          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-50          [-1, 128, 28, 28]             256\n",
      "             ReLU-51          [-1, 128, 28, 28]               0\n",
      "           Conv2d-52          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-53          [-1, 128, 28, 28]             256\n",
      "             ReLU-54          [-1, 128, 28, 28]               0\n",
      "           Conv2d-55          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-56          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-57          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-58          [-1, 512, 28, 28]               0\n",
      "           Conv2d-59          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-60          [-1, 128, 28, 28]             256\n",
      "             ReLU-61          [-1, 128, 28, 28]               0\n",
      "           Conv2d-62          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-63          [-1, 128, 28, 28]             256\n",
      "             ReLU-64          [-1, 128, 28, 28]               0\n",
      "           Conv2d-65          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-66          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-67          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-68          [-1, 512, 28, 28]               0\n",
      "           Conv2d-69          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-70          [-1, 128, 28, 28]             256\n",
      "             ReLU-71          [-1, 128, 28, 28]               0\n",
      "           Conv2d-72          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-73          [-1, 128, 28, 28]             256\n",
      "             ReLU-74          [-1, 128, 28, 28]               0\n",
      "           Conv2d-75          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-76          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-77          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-78          [-1, 512, 28, 28]               0\n",
      "           Conv2d-79          [-1, 256, 28, 28]         131,072\n",
      "      BatchNorm2d-80          [-1, 256, 28, 28]             512\n",
      "             ReLU-81          [-1, 256, 28, 28]               0\n",
      "           Conv2d-82          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-83          [-1, 256, 14, 14]             512\n",
      "             ReLU-84          [-1, 256, 14, 14]               0\n",
      "           Conv2d-85         [-1, 1024, 14, 14]         262,144\n",
      "      BatchNorm2d-86         [-1, 1024, 14, 14]           2,048\n",
      "           Conv2d-87         [-1, 1024, 14, 14]         524,288\n",
      "      BatchNorm2d-88         [-1, 1024, 14, 14]           2,048\n",
      "             ReLU-89         [-1, 1024, 14, 14]               0\n",
      "       Bottleneck-90         [-1, 1024, 14, 14]               0\n",
      "           Conv2d-91          [-1, 256, 14, 14]         262,144\n",
      "      BatchNorm2d-92          [-1, 256, 14, 14]             512\n",
      "             ReLU-93          [-1, 256, 14, 14]               0\n",
      "           Conv2d-94          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-95          [-1, 256, 14, 14]             512\n",
      "             ReLU-96          [-1, 256, 14, 14]               0\n",
      "           Conv2d-97         [-1, 1024, 14, 14]         262,144\n",
      "      BatchNorm2d-98         [-1, 1024, 14, 14]           2,048\n",
      "             ReLU-99         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-100         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-101          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-102          [-1, 256, 14, 14]             512\n",
      "            ReLU-103          [-1, 256, 14, 14]               0\n",
      "          Conv2d-104          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-105          [-1, 256, 14, 14]             512\n",
      "            ReLU-106          [-1, 256, 14, 14]               0\n",
      "          Conv2d-107         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-108         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-109         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-110         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-111          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-112          [-1, 256, 14, 14]             512\n",
      "            ReLU-113          [-1, 256, 14, 14]               0\n",
      "          Conv2d-114          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-115          [-1, 256, 14, 14]             512\n",
      "            ReLU-116          [-1, 256, 14, 14]               0\n",
      "          Conv2d-117         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-118         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-119         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-120         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-121          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-122          [-1, 256, 14, 14]             512\n",
      "            ReLU-123          [-1, 256, 14, 14]               0\n",
      "          Conv2d-124          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-125          [-1, 256, 14, 14]             512\n",
      "            ReLU-126          [-1, 256, 14, 14]               0\n",
      "          Conv2d-127         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-128         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-129         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-130         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-131          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-132          [-1, 256, 14, 14]             512\n",
      "            ReLU-133          [-1, 256, 14, 14]               0\n",
      "          Conv2d-134          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-135          [-1, 256, 14, 14]             512\n",
      "            ReLU-136          [-1, 256, 14, 14]               0\n",
      "          Conv2d-137         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-138         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-139         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-140         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-141          [-1, 512, 14, 14]         524,288\n",
      "     BatchNorm2d-142          [-1, 512, 14, 14]           1,024\n",
      "            ReLU-143          [-1, 512, 14, 14]               0\n",
      "          Conv2d-144            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-145            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-146            [-1, 512, 7, 7]               0\n",
      "          Conv2d-147           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-148           [-1, 2048, 7, 7]           4,096\n",
      "          Conv2d-149           [-1, 2048, 7, 7]       2,097,152\n",
      "     BatchNorm2d-150           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-151           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-152           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-153            [-1, 512, 7, 7]       1,048,576\n",
      "     BatchNorm2d-154            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-155            [-1, 512, 7, 7]               0\n",
      "          Conv2d-156            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-157            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-158            [-1, 512, 7, 7]               0\n",
      "          Conv2d-159           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-160           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-161           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-162           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-163            [-1, 512, 7, 7]       1,048,576\n",
      "     BatchNorm2d-164            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-165            [-1, 512, 7, 7]               0\n",
      "          Conv2d-166            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-167            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-168            [-1, 512, 7, 7]               0\n",
      "          Conv2d-169           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-170           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-171           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-172           [-1, 2048, 7, 7]               0\n",
      "================================================================\n",
      "Total params: 23,508,032\n",
      "Trainable params: 23,508,032\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 286.54\n",
      "Params size (MB): 89.68\n",
      "Estimated Total Size (MB): 376.79\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model, (3, 224, 224),device=device.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 256, 400]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 256, 400]             128\n",
      "              ReLU-3         [-1, 64, 256, 400]               0\n",
      "         MaxPool2d-4         [-1, 64, 128, 200]               0\n",
      "            Conv2d-5         [-1, 64, 128, 200]           4,096\n",
      "       BatchNorm2d-6         [-1, 64, 128, 200]             128\n",
      "              ReLU-7         [-1, 64, 128, 200]               0\n",
      "            Conv2d-8         [-1, 64, 128, 200]          36,864\n",
      "       BatchNorm2d-9         [-1, 64, 128, 200]             128\n",
      "             ReLU-10         [-1, 64, 128, 200]               0\n",
      "           Conv2d-11        [-1, 256, 128, 200]          16,384\n",
      "      BatchNorm2d-12        [-1, 256, 128, 200]             512\n",
      "           Conv2d-13        [-1, 256, 128, 200]          16,384\n",
      "      BatchNorm2d-14        [-1, 256, 128, 200]             512\n",
      "             ReLU-15        [-1, 256, 128, 200]               0\n",
      "       Bottleneck-16        [-1, 256, 128, 200]               0\n",
      "           Conv2d-17         [-1, 64, 128, 200]          16,384\n",
      "      BatchNorm2d-18         [-1, 64, 128, 200]             128\n",
      "             ReLU-19         [-1, 64, 128, 200]               0\n",
      "           Conv2d-20         [-1, 64, 128, 200]          36,864\n",
      "      BatchNorm2d-21         [-1, 64, 128, 200]             128\n",
      "             ReLU-22         [-1, 64, 128, 200]               0\n",
      "           Conv2d-23        [-1, 256, 128, 200]          16,384\n",
      "      BatchNorm2d-24        [-1, 256, 128, 200]             512\n",
      "             ReLU-25        [-1, 256, 128, 200]               0\n",
      "       Bottleneck-26        [-1, 256, 128, 200]               0\n",
      "           Conv2d-27         [-1, 64, 128, 200]          16,384\n",
      "      BatchNorm2d-28         [-1, 64, 128, 200]             128\n",
      "             ReLU-29         [-1, 64, 128, 200]               0\n",
      "           Conv2d-30         [-1, 64, 128, 200]          36,864\n",
      "      BatchNorm2d-31         [-1, 64, 128, 200]             128\n",
      "             ReLU-32         [-1, 64, 128, 200]               0\n",
      "           Conv2d-33        [-1, 256, 128, 200]          16,384\n",
      "      BatchNorm2d-34        [-1, 256, 128, 200]             512\n",
      "             ReLU-35        [-1, 256, 128, 200]               0\n",
      "       Bottleneck-36        [-1, 256, 128, 200]               0\n",
      "           Conv2d-37        [-1, 128, 128, 200]          32,768\n",
      "      BatchNorm2d-38        [-1, 128, 128, 200]             256\n",
      "             ReLU-39        [-1, 128, 128, 200]               0\n",
      "           Conv2d-40         [-1, 128, 64, 100]         147,456\n",
      "      BatchNorm2d-41         [-1, 128, 64, 100]             256\n",
      "             ReLU-42         [-1, 128, 64, 100]               0\n",
      "           Conv2d-43         [-1, 512, 64, 100]          65,536\n",
      "      BatchNorm2d-44         [-1, 512, 64, 100]           1,024\n",
      "           Conv2d-45         [-1, 512, 64, 100]         131,072\n",
      "      BatchNorm2d-46         [-1, 512, 64, 100]           1,024\n",
      "             ReLU-47         [-1, 512, 64, 100]               0\n",
      "       Bottleneck-48         [-1, 512, 64, 100]               0\n",
      "           Conv2d-49         [-1, 128, 64, 100]          65,536\n",
      "      BatchNorm2d-50         [-1, 128, 64, 100]             256\n",
      "             ReLU-51         [-1, 128, 64, 100]               0\n",
      "           Conv2d-52         [-1, 128, 64, 100]         147,456\n",
      "      BatchNorm2d-53         [-1, 128, 64, 100]             256\n",
      "             ReLU-54         [-1, 128, 64, 100]               0\n",
      "           Conv2d-55         [-1, 512, 64, 100]          65,536\n",
      "      BatchNorm2d-56         [-1, 512, 64, 100]           1,024\n",
      "             ReLU-57         [-1, 512, 64, 100]               0\n",
      "       Bottleneck-58         [-1, 512, 64, 100]               0\n",
      "           Conv2d-59         [-1, 128, 64, 100]          65,536\n",
      "      BatchNorm2d-60         [-1, 128, 64, 100]             256\n",
      "             ReLU-61         [-1, 128, 64, 100]               0\n",
      "           Conv2d-62         [-1, 128, 64, 100]         147,456\n",
      "      BatchNorm2d-63         [-1, 128, 64, 100]             256\n",
      "             ReLU-64         [-1, 128, 64, 100]               0\n",
      "           Conv2d-65         [-1, 512, 64, 100]          65,536\n",
      "      BatchNorm2d-66         [-1, 512, 64, 100]           1,024\n",
      "             ReLU-67         [-1, 512, 64, 100]               0\n",
      "       Bottleneck-68         [-1, 512, 64, 100]               0\n",
      "           Conv2d-69         [-1, 128, 64, 100]          65,536\n",
      "      BatchNorm2d-70         [-1, 128, 64, 100]             256\n",
      "             ReLU-71         [-1, 128, 64, 100]               0\n",
      "           Conv2d-72         [-1, 128, 64, 100]         147,456\n",
      "      BatchNorm2d-73         [-1, 128, 64, 100]             256\n",
      "             ReLU-74         [-1, 128, 64, 100]               0\n",
      "           Conv2d-75         [-1, 512, 64, 100]          65,536\n",
      "      BatchNorm2d-76         [-1, 512, 64, 100]           1,024\n",
      "             ReLU-77         [-1, 512, 64, 100]               0\n",
      "       Bottleneck-78         [-1, 512, 64, 100]               0\n",
      "           Conv2d-79         [-1, 256, 64, 100]         131,072\n",
      "      BatchNorm2d-80         [-1, 256, 64, 100]             512\n",
      "             ReLU-81         [-1, 256, 64, 100]               0\n",
      "           Conv2d-82          [-1, 256, 32, 50]         589,824\n",
      "      BatchNorm2d-83          [-1, 256, 32, 50]             512\n",
      "             ReLU-84          [-1, 256, 32, 50]               0\n",
      "           Conv2d-85         [-1, 1024, 32, 50]         262,144\n",
      "      BatchNorm2d-86         [-1, 1024, 32, 50]           2,048\n",
      "           Conv2d-87         [-1, 1024, 32, 50]         524,288\n",
      "      BatchNorm2d-88         [-1, 1024, 32, 50]           2,048\n",
      "             ReLU-89         [-1, 1024, 32, 50]               0\n",
      "       Bottleneck-90         [-1, 1024, 32, 50]               0\n",
      "           Conv2d-91          [-1, 256, 32, 50]         262,144\n",
      "      BatchNorm2d-92          [-1, 256, 32, 50]             512\n",
      "             ReLU-93          [-1, 256, 32, 50]               0\n",
      "           Conv2d-94          [-1, 256, 32, 50]         589,824\n",
      "      BatchNorm2d-95          [-1, 256, 32, 50]             512\n",
      "             ReLU-96          [-1, 256, 32, 50]               0\n",
      "           Conv2d-97         [-1, 1024, 32, 50]         262,144\n",
      "      BatchNorm2d-98         [-1, 1024, 32, 50]           2,048\n",
      "             ReLU-99         [-1, 1024, 32, 50]               0\n",
      "      Bottleneck-100         [-1, 1024, 32, 50]               0\n",
      "          Conv2d-101          [-1, 256, 32, 50]         262,144\n",
      "     BatchNorm2d-102          [-1, 256, 32, 50]             512\n",
      "            ReLU-103          [-1, 256, 32, 50]               0\n",
      "          Conv2d-104          [-1, 256, 32, 50]         589,824\n",
      "     BatchNorm2d-105          [-1, 256, 32, 50]             512\n",
      "            ReLU-106          [-1, 256, 32, 50]               0\n",
      "          Conv2d-107         [-1, 1024, 32, 50]         262,144\n",
      "     BatchNorm2d-108         [-1, 1024, 32, 50]           2,048\n",
      "            ReLU-109         [-1, 1024, 32, 50]               0\n",
      "      Bottleneck-110         [-1, 1024, 32, 50]               0\n",
      "          Conv2d-111          [-1, 256, 32, 50]         262,144\n",
      "     BatchNorm2d-112          [-1, 256, 32, 50]             512\n",
      "            ReLU-113          [-1, 256, 32, 50]               0\n",
      "          Conv2d-114          [-1, 256, 32, 50]         589,824\n",
      "     BatchNorm2d-115          [-1, 256, 32, 50]             512\n",
      "            ReLU-116          [-1, 256, 32, 50]               0\n",
      "          Conv2d-117         [-1, 1024, 32, 50]         262,144\n",
      "     BatchNorm2d-118         [-1, 1024, 32, 50]           2,048\n",
      "            ReLU-119         [-1, 1024, 32, 50]               0\n",
      "      Bottleneck-120         [-1, 1024, 32, 50]               0\n",
      "          Conv2d-121          [-1, 256, 32, 50]         262,144\n",
      "     BatchNorm2d-122          [-1, 256, 32, 50]             512\n",
      "            ReLU-123          [-1, 256, 32, 50]               0\n",
      "          Conv2d-124          [-1, 256, 32, 50]         589,824\n",
      "     BatchNorm2d-125          [-1, 256, 32, 50]             512\n",
      "            ReLU-126          [-1, 256, 32, 50]               0\n",
      "          Conv2d-127         [-1, 1024, 32, 50]         262,144\n",
      "     BatchNorm2d-128         [-1, 1024, 32, 50]           2,048\n",
      "            ReLU-129         [-1, 1024, 32, 50]               0\n",
      "      Bottleneck-130         [-1, 1024, 32, 50]               0\n",
      "          Conv2d-131          [-1, 256, 32, 50]         262,144\n",
      "     BatchNorm2d-132          [-1, 256, 32, 50]             512\n",
      "            ReLU-133          [-1, 256, 32, 50]               0\n",
      "          Conv2d-134          [-1, 256, 32, 50]         589,824\n",
      "     BatchNorm2d-135          [-1, 256, 32, 50]             512\n",
      "            ReLU-136          [-1, 256, 32, 50]               0\n",
      "          Conv2d-137         [-1, 1024, 32, 50]         262,144\n",
      "     BatchNorm2d-138         [-1, 1024, 32, 50]           2,048\n",
      "            ReLU-139         [-1, 1024, 32, 50]               0\n",
      "      Bottleneck-140         [-1, 1024, 32, 50]               0\n",
      "          Conv2d-141          [-1, 512, 32, 50]         524,288\n",
      "     BatchNorm2d-142          [-1, 512, 32, 50]           1,024\n",
      "            ReLU-143          [-1, 512, 32, 50]               0\n",
      "          Conv2d-144          [-1, 512, 16, 25]       2,359,296\n",
      "     BatchNorm2d-145          [-1, 512, 16, 25]           1,024\n",
      "            ReLU-146          [-1, 512, 16, 25]               0\n",
      "          Conv2d-147         [-1, 2048, 16, 25]       1,048,576\n",
      "     BatchNorm2d-148         [-1, 2048, 16, 25]           4,096\n",
      "          Conv2d-149         [-1, 2048, 16, 25]       2,097,152\n",
      "     BatchNorm2d-150         [-1, 2048, 16, 25]           4,096\n",
      "            ReLU-151         [-1, 2048, 16, 25]               0\n",
      "      Bottleneck-152         [-1, 2048, 16, 25]               0\n",
      "          Conv2d-153          [-1, 512, 16, 25]       1,048,576\n",
      "     BatchNorm2d-154          [-1, 512, 16, 25]           1,024\n",
      "            ReLU-155          [-1, 512, 16, 25]               0\n",
      "          Conv2d-156          [-1, 512, 16, 25]       2,359,296\n",
      "     BatchNorm2d-157          [-1, 512, 16, 25]           1,024\n",
      "            ReLU-158          [-1, 512, 16, 25]               0\n",
      "          Conv2d-159         [-1, 2048, 16, 25]       1,048,576\n",
      "     BatchNorm2d-160         [-1, 2048, 16, 25]           4,096\n",
      "            ReLU-161         [-1, 2048, 16, 25]               0\n",
      "      Bottleneck-162         [-1, 2048, 16, 25]               0\n",
      "          Conv2d-163          [-1, 512, 16, 25]       1,048,576\n",
      "     BatchNorm2d-164          [-1, 512, 16, 25]           1,024\n",
      "            ReLU-165          [-1, 512, 16, 25]               0\n",
      "          Conv2d-166          [-1, 512, 16, 25]       2,359,296\n",
      "     BatchNorm2d-167          [-1, 512, 16, 25]           1,024\n",
      "            ReLU-168          [-1, 512, 16, 25]               0\n",
      "          Conv2d-169         [-1, 2048, 16, 25]       1,048,576\n",
      "     BatchNorm2d-170         [-1, 2048, 16, 25]           4,096\n",
      "            ReLU-171         [-1, 2048, 16, 25]               0\n",
      "      Bottleneck-172         [-1, 2048, 16, 25]               0\n",
      "================================================================\n",
      "Total params: 23,508,032\n",
      "Trainable params: 23,508,032\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 4.69\n",
      "Forward/backward pass size (MB): 2339.06\n",
      "Params size (MB): 89.68\n",
      "Estimated Total Size (MB): 2433.43\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model, (3, 512, 800),device=device.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-06T10:21:41.226006Z",
     "start_time": "2023-12-06T10:21:41.089899Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), PATH_MODEL+'model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FPN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-06T11:34:13.207827Z",
     "start_time": "2023-12-06T11:34:13.201822Z"
    }
   },
   "outputs": [],
   "source": [
    "from model.FeaturesPyramid import FeaturesPyramid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-06T11:34:17.172710Z",
     "start_time": "2023-12-06T11:34:17.132676Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-06T11:34:20.132377Z",
     "start_time": "2023-12-06T11:34:17.808841Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output P3 shape: torch.Size([1, 256, 28, 28])\n",
      "Output P4 shape: torch.Size([1, 256, 14, 14])\n",
      "Output P5 shape: torch.Size([1, 256, 7, 7])\n",
      "Output P6 shape: torch.Size([1, 256, 4, 4])\n",
      "Output P7 shape: torch.Size([1, 256, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "in_channels_list = [512, 1024, 2048]\n",
    "out_channels = 256\n",
    "img_size_c3 = 56\n",
    "inputs = []\n",
    "inputs = [torch.randn(1, c, img_size_c3//(2**i), img_size_c3//(2**i)).to(device) for i, c in enumerate(in_channels_list, start=1)]\n",
    "\n",
    "# Utwórz instancję klasy FeaturesPyramid\n",
    "fpn = FeaturesPyramid(in_channels_list, out_channels).to(device)\n",
    "\n",
    "# Wywołaj funkcję forward na danych wejściowych\n",
    "outputs = fpn(inputs)\n",
    "\n",
    "# Wyświetl wyniki\n",
    "for i, output in enumerate(outputs):\n",
    "    print(f'Output P{i + 3} shape: {output.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-06T11:34:21.661272Z",
     "start_time": "2023-12-06T11:34:21.656268Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 512, 28, 28]),\n",
       " torch.Size([1, 1024, 14, 14]),\n",
       " torch.Size([1, 2048, 7, 7]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[0].size(),inputs[1].size(),inputs[2].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-06T11:34:23.272742Z",
     "start_time": "2023-12-06T11:34:23.267738Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 512, 28, 28), (1, 1024, 14, 14), (1, 2048, 7, 7), tuple, int)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s0 = tuple(inputs[0].size()); s1=tuple(inputs[1].size()); s2=tuple(inputs[2].size())\n",
    "s0,s1,s2, type(s0), type(s0[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-06T11:49:38.990301Z",
     "start_time": "2023-12-06T11:49:38.986799Z"
    }
   },
   "outputs": [],
   "source": [
    "# https://github.com/sksq96/pytorch-summary\n",
    "# summary(fpn,input_size=[s0,s1,s2],device=device.type)\n",
    "# summary(fpn,input_size=inputs,device=device.type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RetinaNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-06T12:05:18.831366Z",
     "start_time": "2023-12-06T12:05:17.667394Z"
    }
   },
   "outputs": [],
   "source": [
    "from model.RetinaNet import RetinaNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "RetNet = RetinaNet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = torch.randn(1,3, 512, 800).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 512, 800])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_RN = RetNet(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, output \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutputs_RN\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOutput P\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m3\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "for i, output in enumerate(outputs_RN):\n",
    "    print(f'Output P{i + 3} shape: {output.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
